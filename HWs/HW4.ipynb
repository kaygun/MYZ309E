{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2f4e677-71b4-4ff2-bc79-f861e29e3b93",
   "metadata": {},
   "source": [
    "# HW4\n",
    "\n",
    "Overall rules:\n",
    "\n",
    "- Do not split your answers into separate files. All answers must be in a single jupyter notebook. \n",
    "- Obtain all required remote data using the appropriate API unless otherwise is specified.\n",
    "- Refrain from using code comments to explain what has been done. Document your steps by writing appropriate markdown cells in your notebook.\n",
    "- Avoid duplicating code by copying and pasting it from one cell to another. If copying and pasting is necessary, develop a suitable function for the task at hand and call that function.\n",
    "- When providing parameters to a function, never use global variables. Instead, always pass parameters explicitly and always make use of local variables.\n",
    "- Document your use of LLM models (ChatGPT, Claude, Code Pilot etc). Either take screenshots of your steps and include them with this notebook, or give me a full log (both questions and answers) in a markdown file named HW4-LLM-LOG.md.\n",
    "\n",
    "Failure to adhere to these guidelines will result in a 15-point deduction for each infraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd587c-1979-4f49-bc0e-378bbcbb5813",
   "metadata": {},
   "source": [
    "## Q1\n",
    "\n",
    "In this problem, you will compare the performance of several supervised learning models on the CIFAR-10 dataset available through `tensorflow_datasets`. The CIFAR-10 dataset consists of 60,000 $32 \\times 32$ color images in 10 classes, with 6,000 images per class. To simplify the computational requirements and focus on core algorithmic aspects, you may preprocess the images by converting them to grayscale.\n",
    "\n",
    "1. Load the CIFAR-10 dataset using the `tensorflow_datasets` library. Preprocess the dataset by:\n",
    "   - Converting the images to grayscale,\n",
    "   - Flattening the image into a vector (if necessary) for models that require vector inputs,\n",
    "   - Normalizing pixel values to the $[0,1]$ range.\n",
    "\n",
    "2. Train and evaluate the following models on the dataset:\n",
    "   - **Logistic Regression** (one-vs-rest and one-vs-one),\n",
    "   - **Support Vector Machine (SVM)** with:\n",
    "     - A linear kernel,\n",
    "     - A Gaussian (RBF) kernel,\n",
    "     - A polynomial kernel,\n",
    "   - **A simple neural network** consisting of:\n",
    "     - One or two hidden layers,\n",
    "     - Nonlinear activation functions (such as ReLU or tanh),\n",
    "     - A softmax output layer for classification.\n",
    "\n",
    "3. For each model, report:\n",
    "   - The overall test set classification accuracy,\n",
    "   - The confusion matrix,\n",
    "   - Precision, recall, and F1-score per class.\n",
    "\n",
    "4. Conduct a **statistical error analysis**:\n",
    "   - Compute $95\\%$ confidence intervals for the test set accuracy estimates (e.g., using the binomial proportion confidence interval),\n",
    "   - Discuss any significant differences between model performances.\n",
    "\n",
    "5. Discuss the **computational trade-offs**:\n",
    "   - Measure and report the **training time** and **inference time** for each model (e.g., using simple timing functions),\n",
    "   - Measure and report **memory usage** where feasible (e.g., by estimating the number of parameters or using profiling tools),\n",
    "   - Reflect on how model complexity (both in terms of runtime and memory) correlates with performance.\n",
    "\n",
    "6. Conclude by discussing the observed trade-offs between **model simplicity**, **computational cost**, and **predictive accuracy**.\n",
    "\n",
    "You may use `tensorflow`, `pytorch` or `keras` for neural network model implementation. Clearly indicate any hyperparameter choices (e.g., regularization strength, kernel parameters, number of neurons in hidden layers). Ensure that your experimental code supports reproducibility (by fixing random seeds where applicable).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ea4678-e7f8-4bca-8eea-2ba4f7d8b4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d901ce5e-811a-44b0-9f96-10fde628676d",
   "metadata": {},
   "source": [
    "## Q2\n",
    "\n",
    "In this assignment, you will explore the application of boosting algorithms to a medical image classification problem. The dataset is **PneumoniaMNIST** from the **MedMNIST** collection, available through `tensorflow_datasets` under `medmnist.pneumoniamnist`. PneumoniaMNIST consists of chest X-ray images labeled either as **normal** or **pneumonia**.\n",
    "\n",
    "The goal is to predict whether a patient shows signs of pneumonia based on their chest X-ray image.\n",
    "\n",
    "1. Load the PneumoniaMNIST dataset using the `tensorflow_datasets` library. Preprocess the dataset by:\n",
    "   - Normalizing the pixel values to $[0,1]$,\n",
    "   - Flattening the $28\\times28$ images into vectors suitable for tabular classifiers.\n",
    "\n",
    "2. Train and evaluate the following models:\n",
    "   - **Gradient Boosted Decision Trees (GBDT)** using **XGBoost**,\n",
    "   - **AdaBoost** with **decision stumps** (single-level decision trees) as weak learners,\n",
    "   - **Gradient Boosting Classifier** using **LightGBM** or **sklearn's GradientBoostingClassifier**.\n",
    "\n",
    "3. For each model report the test set classification **accuracy**, **precision**, **recall**, **F1-score**, and do a proper error analysis on the values you calculated.\n",
    "\n",
    "4. Interpret the learned models:\n",
    "   - Extract and rank the most important pixels (features) contributing to the classification decision (feature importance analysis).\n",
    "   - Visualize and interpret these \"important pixels\" on the original $28\\times28$ image grid. Discuss whether they align with medical intuition (e.g., lung region emphasis).\n",
    "\n",
    "5. Discuss computational aspects:\n",
    "   - Measure and report the **training time** and **inference time** for each boosting model,\n",
    "   - Report and compare the **model size** (e.g., number of leaves, total size of the trained model).\n",
    "\n",
    "6. Write a final summary:\n",
    "   - Summarize the strengths and weaknesses you observed for each boosting method in this specific small-image classification task,\n",
    "   - Comment on whether boosting methods are well-suited for this type of structured low-dimensional image data compared to neural network approaches.\n",
    "\n",
    "Hyperparameters such as learning rate, number of estimators, and maximum tree depth should be selected using 5-fold cross-validation or a separate validation split. Pay special attention to **early stopping** where appropriate to avoid overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3e5f1d-2d7b-4d19-b049-1aaea8fdbb63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8837da7d-ed5e-43d1-a9c0-6400ea8691d6",
   "metadata": {},
   "source": [
    "## Q3\n",
    "\n",
    "In this question, you will investigate the use of **autoencoders** for compressing high-dimensional text data into a lower-dimensional latent space. You will use the **IMDB movie reviews dataset** from `tensorflow_datasets` and develop a pipeline based on **count vectorization**, followed by a **fully-connected autoencoder**.  This question focuses on **unsupervised representation learning** and reconstruction accuracy in the **bag-of-words (BoW)** paradigm.\n",
    "\n",
    "#### **Part I: Preprocessing Pipeline**\n",
    "\n",
    "1. Load the `imdb_reviews` dataset using `tensorflow_datasets`.\n",
    "2. Construct a preprocessing pipeline consisting of the following steps:\n",
    "   - **Text cleaning**: remove punctuation and convert all text to lowercase.\n",
    "   - **Tokenization**: split the review into word tokens.\n",
    "   - **Count-based vectorization**:\n",
    "     - Use `sklearn.feature_extraction.text.CountVectorizer`,\n",
    "     - Limit the vocabulary to the top $V = 5000$ most frequent words,\n",
    "     - Represent each review as a **$V$-dimensional sparse count vector**.\n",
    "\n",
    "3. Optionally, apply TF scaling or binary indicator (0/1) encoding to the count vectors. Justify your choice.\n",
    "\n",
    "#### **Part II: Autoencoder Architecture**\n",
    "\n",
    "4. Build a **fully-connected feedforward autoencoder** in TensorFlow/Keras:\n",
    "   - The **input layer** accepts a $V$-dimensional BoW vector,\n",
    "   - The **encoder** compresses it through one or more dense layers to a **latent space** of dimension $d \\ll V$ (e.g., $d = 32$ or $64$),\n",
    "   - The **decoder** maps the latent representation back to a $V$-dimensional output using symmetric architecture,\n",
    "   - Use **sigmoid activation** on the final output layer to model per-word presence/absence (binary cross-entropy loss),\n",
    "   - Apply **dropout** and/or **L2 regularization** to mitigate overfitting.\n",
    "\n",
    "#### **Part III: Training and Evaluation**\n",
    "\n",
    "5. Train the autoencoder on the training portion of the dataset using:\n",
    "   - Mini-batch SGD or Adam optimizer,\n",
    "   - Binary cross-entropy loss,\n",
    "   - A held-out validation set for early stopping.\n",
    "\n",
    "6. Evaluate the quality of the trained autoencoder on the test set:\n",
    "   - For each reconstructed output $\\hat{x}$ and corresponding input $x$, compute the **binary prediction** $\\hat{x}_i = 1$ if $\\hat{x}_i > 0.5$,\n",
    "   - Compute **per-sample accuracy**: proportion of correctly reconstructed binary entries per BoW vector together with a proper error analysis,\n",
    "   - Report the **mean accuracy** across all test samples together with a proper error analysis.\n",
    "\n",
    "7. In addition, report:\n",
    "   - The total number of parameters in the model,\n",
    "   - The average compression ratio (input dimension / latent dimension),\n",
    "   - A few example reconstructions: for 5 randomly chosen reviews, list the top-10 most frequent words in the original and reconstructed BoW vectors. Discuss any semantic degradation or preservation.\n",
    "\n",
    "#### **Part IV: Latent Space Visualization and Interpretation**\n",
    "\n",
    "8. Extract the **latent representations** of 1000 test reviews.\n",
    "9. Use PCA to reduce the $d$-dimensional latent codes to 2D and visualize the resulting plot.\n",
    "   - Color the points based on **sentiment label** (positive or negative, available in the dataset but not used during training),\n",
    "   - Discuss whether the autoencoder latent space **implicitly clusters** sentences by sentiment, even though the model was trained in an unsupervised manner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beef9d3-14ef-4b45-9691-4c236e98ef7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

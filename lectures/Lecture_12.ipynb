{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6107038a-1ca3-4112-81c9-5938373fc6cd",
   "metadata": {},
   "source": [
    "# Lecture 12 (Neural Networks Continued)\n",
    "\n",
    "## Convolutional Networks\n",
    "\n",
    "Having covered the theory of classical fully connected feedforward networks — where the fundamental building block is a composition of affine maps and nonlinear activation functions — it is now natural to seek architectures that can exploit additional **geometric structure** present in certain classes of data, particularly images, spatial data, or any modality exhibiting **locality** and **translation invariance**.\n",
    "\n",
    "Convolutional Neural Networks, or CNNs, arise precisely as a mathematically principled response to this need. Formally, in a standard fully connected layer, each neuron computes a transformation of the form\n",
    "$$\n",
    "x \\mapsto \\sigma(Wx + b),\n",
    "$$\n",
    "where $W \\in \\mathbb{R}^{m \\times d}$ is a dense weight matrix, $b \\in \\mathbb{R}^m$ is a bias vector, $\\sigma$ is an activation function, and $x \\in \\mathbb{R}^d$ is the input.\n",
    "\n",
    "In contrast, in a convolutional layer, rather than allowing arbitrary dense interactions between all input and output units, one restricts the transformation to be **local** and **shared** across different spatial regions. Let us model the input as a function\n",
    "$$\n",
    "x : \\Omega \\subset \\mathbb{Z}^2 \\to \\mathbb{R},\n",
    "$$\n",
    "where $\\Omega$ is a discrete rectangular domain, typically corresponding to pixel locations of a grayscale image. For color images, $x$ would map into $\\mathbb{R}^3$, corresponding to RGB channels. Given a small filter, or **kernel**, represented as a function\n",
    "$$\n",
    "k : \\Delta \\subset \\mathbb{Z}^2 \\to \\mathbb{R},\n",
    "$$\n",
    "where $\\Delta$ is typically a small region such as $\\{0,1,2\\} \\times \\{0,1,2\\}$ (corresponding to a $3 \\times 3$ filter), the **convolution** of $k$ with $x$ at position $(u,v)$ is defined by\n",
    "$$\n",
    "(k * x)(u,v) = \\sum_{(s,t) \\in \\Delta} k(s,t) \\, x(u-s, v-t).\n",
    "$$\n",
    "Thus, the output at each spatial location $(u,v)$ depends only on a small neighborhood of the input centered at $(u,v)$, determined by the size of the kernel $\\Delta$. A convolutional layer consists of multiple such kernels $\\{k_i\\}_{i=1}^n$, each producing its own feature map\n",
    "$$\n",
    "y_i(u,v) = \\sigma\\left( (k_i * x)(u,v) + b_i \\right),\n",
    "$$\n",
    "where $\\sigma$ is a nonlinear activation function such as ReLU, and $b_i \\in \\mathbb{R}$ is a bias term. The key mathematical principles embodied in CNNs are thus:\n",
    "\n",
    "1. **local connectivity**: neurons are connected only to small spatial regions of the input.\n",
    "\n",
    "2. **parameter sharing**: the same kernel $k_i$ is applied across all spatial locations, greatly reducing the number of parameters and introducing a strong inductive bias toward translation invariance.\n",
    "\n",
    "3. **equivariance to translation**: if the input is shifted, the output feature maps shift correspondingly, preserving spatial structure.\n",
    "\n",
    "These properties make CNNs particularly well-suited for tasks where the relevant features are local and their precise spatial location is less critical than their relative arrangement.\n",
    "\n",
    "\n",
    "The construction of a CNN proceeds hierarchically. At the first layer, low-level features such as edges, corners, and simple textures are detected. At deeper layers, the network composes these simple features into progressively more abstract and global representations: motifs, parts, objects. Formally, given an input $x^{(0)} = x$, each layer $l$ computes\n",
    "$$\n",
    "x^{(l)} = \\sigma\\left( k^{(l)} * x^{(l-1)} + b^{(l)} \\right),\n",
    "$$\n",
    "where $k^{(l)}$ and $b^{(l)}$ are the learnable parameters of layer $l$. Typically, convolutional layers are interleaved with **pooling layers**, which downsample the spatial dimensions to introduce further invariance to small translations or distortions. A common form of pooling is **max pooling**, defined for a small region $R \\subset \\Omega$ as\n",
    "$$\n",
    "\\text{MaxPool}(x)(u,v) = \\max_{(s,t) \\in R} x(u+s,v+t),\n",
    "$$\n",
    "which retains only the maximum activation within each local neighborhood.  Thus, a typical CNN architecture consists of alternating convolutional layers, nonlinearities, and pooling layers, culminating in fully connected layers for the final classification or regression tasks.\n",
    "\n",
    "---\n",
    "\n",
    "From the perspective of backpropagation, the critical difference with fully connected networks lies in the structure of the Jacobian matrices involved. Whereas in fully connected layers the Jacobians are dense, in convolutional layers they exhibit a **highly sparse, structured pattern** reflecting local connections and weight sharing. However, backpropagation through convolutional layers is entirely analogous in principle: one applies the chain rule, computes local gradients with respect to the weights, inputs, and outputs, and updates parameters accordingly. It is worth noting that the convolution operation is linear, hence differentiable, and the pooling operations are piecewise differentiable, so standard gradient-based optimization techniques such as stochastic gradient descent (SGD) or Adam are applicable without difficulty.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e23ace-c720-4a46-9086-e691f8b3c854",
   "metadata": {},
   "source": [
    "## An example in PyTorch\n",
    "\n",
    "Let us now proceed formally to construct a **worked example** of a **Convolutional Neural Network (CNN)** implemented in **PyTorch**, trained on the classical **digits dataset**. For mathematical clarity, we shall work with the **scikit-learn digits dataset**, consisting of $8 \\times 8$ grayscale images of handwritten digits $\\{0,1,\\dots,9\\}$.  Each image $x$ can be modeled as a function\n",
    "$$\n",
    "x: \\{0,1,\\dots,7\\}^2 \\to \\mathbb{R},\n",
    "$$\n",
    "with pixel intensities normalized to $[0,1]$. The classification task consists of learning a function\n",
    "$$\n",
    "f_\\theta : \\mathbb{R}^{8 \\times 8} \\to \\{0,1,\\dots,9\\},\n",
    "$$\n",
    "mapping each input image to its corresponding digit class.  The CNN will be trained to minimize the empirical risk associated to the cross-entropy loss between predicted and true labels. Let us now proceed systematically through the complete PyTorch implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c295ab0-affe-41b1-ad3b-88274dc432ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da1e2dd4-ec74-4385-9bd0-21f607b647e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X = digits.images  # Shape (1797, 8, 8)\n",
    "y = digits.target  # Shape (1797,)\n",
    "\n",
    "X = X / 16.0\n",
    "X = X[:, None, :, :]  # Add channel dimension: (1797, 1, 8, 8)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1f266ff-3f63-4cda-a0df-2eabe652b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),         \n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(32 * 2 * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.reshape(x.size(0), -1)  # Flatten\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a123677d-0700-4493-9952-bb3d761e05a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e79c0e5-943c-4c75-b6a2-e11c588acdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 0.1401, Accuracy: 0.9645\n",
      "Epoch 20/50, Loss: 0.0486, Accuracy: 0.9868\n",
      "Epoch 30/50, Loss: 0.0139, Accuracy: 0.9993\n",
      "Epoch 40/50, Loss: 0.0076, Accuracy: 0.9993\n",
      "Epoch 50/50, Loss: 0.0032, Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss / len(train_loader):.4f}, Accuracy: {correct/total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5770aa1c-5005-4c1c-8627-1d1714ed2b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9972\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    _, predicted = outputs.max(1)\n",
    "    accuracy = (predicted == y_test).float().mean().item()\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "def plot_predictions(images, true_labels, pred_labels, num_images=10):\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n",
    "    for i in range(num_images):\n",
    "        axes[i].imshow(images[i,0], cmap='gray')\n",
    "        axes[i].set_title(f\"True: {true_labels[i]}\\nPred: {pred_labels[i]}\")\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "plot_predictions(X_test.numpy(), y_test.numpy(), predicted.numpy(), num_images=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b898b7-4142-4b07-becc-9e5bdb9c9499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

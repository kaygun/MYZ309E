{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8af2fc52-ec87-4423-8909-a6bc970556ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Our Class Plan in One Big Graph\n",
    "\n",
    "![Course Plan](../images/ml.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b04e873-36f9-4bcc-bede-3abe86980cfe",
   "metadata": {},
   "source": [
    "# Lecture 9: Ensemble Learning\n",
    "\n",
    "Ensemble learning is a type of machine learning where the learning algorithm combines multiple models to improve its predictive performance. The fundamental idea behind ensemble learning is that aggregating multiple models can yield a predictor with lower variance or bias than individual models. This is especially powerful when the individual predictors make different kinds of errors. In supervised learning, the prediction error can be decomposed as:\n",
    "$$\n",
    "\\mathbb{E}[(\\hat{f}(x) - f(x))^2] = \\text{Bias}^2 + \\text{Variance} + \\text{Irreducible Noise}\n",
    "$$\n",
    "Ensemble methods work by reducing the variance term while keeping bias controlled.\n",
    "\n",
    "## Combining different random variables\n",
    "\n",
    "When we combine different random variables into an ensemble, the resulting ensemble may exhibit a lower variance than each random variable. This phenomenon arises due to the correlation or covariance structure among the individual random variables.\n",
    "\n",
    "Consider two random variables $X$ and $Y$. The variance of their average is given by:\n",
    "$$\n",
    "\\text{Var}\\left(\\frac{X+Y}{2}\\right) = \\frac{\\text{Var}(X) + \\text{Var}(Y) + 2\\text{Cov}(X,Y)}{4}\n",
    "$$\n",
    "where $\\text{Cov}(X,Y)$ is the covariance between $X$ and $Y$. We can generalize this to $n$ variables:\n",
    "\n",
    "$$\n",
    "\\text{Var}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i \\right) = \\frac{1}{n^2} \\sum_{i=1}^n \\sum_{j=1}^n \\text{Cov}(X_i, X_j)\n",
    "$$\n",
    "\n",
    "When the $X_i$ are uncorrelated, this reduces to $\\text{Var}(\\bar{X}) = \\frac{1}{n} \\text{Var}(X)$, showing how averaging reduces variance linearly with $n$\n",
    "\n",
    "Recall that *correlation* measures the degree to which two random variables change together. \n",
    "$$\n",
    "\\rho_{X,Y} = \\frac{\\text{Cov}(X,Y)}{\\sqrt{\\text{Var}(X)\\text{Var}(Y)}}\n",
    "$$\n",
    "If the *covariance* between two variables is positive, they tend to increase or decrease together; if it's negative, they tend to move in opposite directions. On the other hand, *correlation*, which ranges from -1 to 1, measures the linear relationship between random variables where 1 indicates a perfect positive linear relationship while -1 indicates a perfect negative linear relationship, and 0 indicates no linear relationship.\n",
    "\n",
    "When we combine different random variables where the individual random variables exhibit a low degree of correlation, or even negative covariance, the combined random variable may have reduced variability compared to the individual variables. When the individual random variables' predictions are not correlated, combining them tends to smooth out fluctuations, leading to reduced variability in the combined variable. If the individual variables' predictions are negatively correlated, combining them can cancel out some of the variability, again leading to reduced variability in the combined variable.\n",
    "\n",
    "## An analogy with portfolio design\n",
    "\n",
    "In finance, specifically in portfolio design theory, the goal is often to design a portfolio that achieves a desired level of return while minimizing the risk. The risk in this context is measured in terms of the variance of the returns. This is usually achieved via **portfolio diversification** where risk is reduced by combining different assets. By combining assets with uncorrelated or negatively correlated returns, investors potentially reduce the overall variance of the portfolio and lower the risk without sacrificing returns.\n",
    "\n",
    "Mathematically, the variance of a portfolio composed of assets $X_i$ with weights $w_i\\in [0,1]$ with $1 = \\sum_i w_i$ is:\n",
    "$$\n",
    "\\text{Var}\\left(\\sum_i w_i X_i\\right) = \\sum_i \\sum_j w_i w_j \\text{Cov}(X_i,X_j)\n",
    "$$\n",
    "Diversification involves holding a variety of investments in a portfolio that have different risk-return profiles.  When assets in a portfolio have low or negative correlations with each other, their returns tend to move independently or even in opposite directions over time. Minimizing variance thus involves selecting assets with low or negative covariance. As a result, when these assets are combined in a portfolio, the overall portfolio's variance or risk is reduced due to the offsetting effects of the individual asset returns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059f927f-fbec-4b00-b746-e7abf7ef8afd",
   "metadata": {},
   "source": [
    "### Variance Reduction through Ensemble Averaging\n",
    "\n",
    "When multiple independent models (or estimators) each produce predictions with some random noise, **averaging their predictions** can reduce the overall variance of the combined result.\n",
    "\n",
    "Suppose each base model predicts a value with independent Gaussian noise:\n",
    "$$\n",
    "\\hat{Y}_i \\sim \\mathcal{N}(f(x), \\sigma^2)\n",
    "$$\n",
    "If we average $n$ such models, the ensemble prediction\n",
    "$$\n",
    "\\bar{Y} = \\frac{1}{n} \\sum_{i=1}^n \\hat{Y}_i\n",
    "$$\n",
    "has variance:\n",
    "$$\n",
    "\\text{Var}(\\bar{Y}) = \\frac{\\sigma^2}{n}\n",
    "$$\n",
    "This is a key statistical justification behind **bagging** (bootstrap aggregation) and other ensemble methods: **independent models reduce variance when averaged.**\n",
    "\n",
    "The plot below demonstrates this principle using a simulation. We simulate many ensembles, each consisting of $n$ noisy predictors, and compute the empirical variance of their average. The theoretical curve $\\sigma^2/n$ is also plotted for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12fd5c2e-9b25-438f-a5b5-48561cd30300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_ensembles = [1, 2, 5, 10, 20, 50, 100]  # different ensemble sizes\n",
    "n_samples = 1000  # number of simulated ensembles\n",
    "true_value = 0.0\n",
    "sigma = 1.0  # standard deviation of individual predictor noise\n",
    "\n",
    "variances = []\n",
    "\n",
    "for n in n_ensembles:\n",
    "    # Simulate n independent noisy predictions for each ensemble\n",
    "    predictions = np.random.normal(loc=true_value, scale=sigma, size=(n_samples, n))\n",
    "    ensemble_avg = predictions.mean(axis=1)  # average over ensemble members\n",
    "    var_estimate = np.var(ensemble_avg)\n",
    "    variances.append(var_estimate)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(n_ensembles, variances, marker='o', linestyle='-', label='Empirical variance')\n",
    "plt.plot(n_ensembles, [sigma**2 / n for n in n_ensembles], linestyle='--', label='Theoretical $\\\\sigma^2/n$')\n",
    "plt.xlabel(\"Number of ensemble members\")\n",
    "plt.ylabel(\"Variance of ensemble prediction\")\n",
    "plt.title(\"Variance Reduction through Averaging in Ensembles\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2410d2-b7e4-4b55-bd0c-343d9469919b",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "\n",
    "**Bagging** (Bootstrap Aggregating) is an ensemble method in which multiple models are trained independently, often in parallel, on different subsets of the training data. These subsets are generated by **random sampling with replacement** from the original dataset.\n",
    "\n",
    "Each model is thus trained on a different bootstrap sample. Their predictions are aggregated via:\n",
    "\n",
    "- **Averaging** (for regression),\n",
    "- **Majority voting** (for classification).\n",
    "\n",
    "Bagging reduces **variance** by averaging over multiple high-variance models, each exposed to different noise realizations in the data. This improves prediction accuracy, particularly for unstable base learners.\n",
    "\n",
    "## Boosting\n",
    "\n",
    "**Boosting** is an iterative ensemble method that trains base learners **sequentially**, where each new model focuses on correcting the errors of its predecessors.\n",
    "\n",
    "At each iteration, the algorithm increases the importance (i.e., assigns higher weights) to the instances misclassified by earlier models. The final prediction is obtained by a **weighted combination** of the base models, where each weight reflects the performance of the corresponding learner.\n",
    "\n",
    "Boosting reduces **bias** by focusing learning effort where the model currently performs poorly. It builds a strong composite predictor from a sequence of weak learners.\n",
    "\n",
    "## Comparison of Bagging and Boosting\n",
    "\n",
    "Bagging** improves stability by training models on different views of the data, thus averaging out the noise. It reduces variance but may retain the bias of the base learner. Boosting** focuses learning where the model underperforms, iteratively correcting mistakes and improving bias at the expense of potential variance increase.\n",
    "\n",
    "<center><img width=\"500px\" src=\"../images/bagging_vs_boosting.png\"></center>\n",
    "\n",
    "Bagging and boosting both combine multiple models to enhance prediction accuracy. However, they differ in how these models are trained, combined, and how they handle the biasvariance tradeoff.\n",
    "\n",
    "| Feature | **Bagging** | **Boosting** |\n",
    "|--|-|--|\n",
    "| Objective | Reduce **variance** | Reduce **bias** |\n",
    "| Training Strategy | Parallel, independent models | Sequential, error-focused models |\n",
    "| Data Sampling | Bootstrap (with replacement) | Adaptive weighting or gradient-based |\n",
    "| Instance Weights | Uniform across all models | Higher for misclassified instances |\n",
    "| Aggregation | Averaging (regression), voting (classification) | Weighted sum of models |\n",
    "| Base Model | Often deep or high-variance | Often shallow or weak learners |\n",
    "| Noise Sensitivity | More robust | More sensitive to noise and outliers |\n",
    "| Examples | Random Forest | AdaBoost, Gradient Boosting, XGBoost |\n",
    "\n",
    "\n",
    "### Practical Implications\n",
    "\n",
    "- Use **bagging** when your base model has high variance (e.g., decision trees) and your dataset is noisy.\n",
    "- Use **boosting** when your base model has high bias and you want to refine its predictive capacity.\n",
    "\n",
    "In practice ensemble models such as Random Forest models use bagging on decorrelated trees, and models such as XGBoost and LightGBM use Boosting and gradient optimization.\n",
    "\n",
    "\n",
    "## Ensemble Classification Strategies\n",
    "\n",
    "Having examined bagging and boosting as two fundamental paradigms of ensemble learningeach with its distinct approach to variance reduction, bias correction, and model aggregationwe now turn to ensemble strategies designed specifically for **multi-class classification**. In particular, when our base learners are binary classifiers, we must devise a mechanism for extending them to handle problems involving more than two classes. Two common and widely used frameworks for this purpose are **One-vs-Rest (OvR)** and **One-vs-One (OvO)** classification strategies. These techniques operate at the level of classifier orchestration rather than internal model structure, and can be combined with either bagging or boosting depending on the broader learning context.\n",
    "\n",
    "Many of the ensemble techniques discussed thus far (e.g., decision trees, AdaBoost, gradient boosting) are inherently binary classifiers: they are designed to distinguish between two classes. However, in practice, many classification tasks involve more than two categories. To bridge this gap, we require **meta-strategies** that allow us to extend binary base learners to solve multi-class problems. The two most commonly used approaches are:\n",
    "\n",
    "- **One-vs-Rest (OvR)**: also known as one-against-all, and\n",
    "- **One-vs-One (OvO)**: also called pairwise classification.\n",
    "\n",
    "These strategies are not tied to any specific learning algorithm. Rather, they provide a **systematic framework** for decomposing a $k$-class classification problem into a collection of binary decisions, enabling the use of ensemble methods even when the base learner is inherently binary. Importantly, OvR and OvO can be combined with either **bagging** or **boosting** depending on the models desired inductive bias, computational constraints, or performance goals.\n",
    "\n",
    "We now examine these classification strategies in detail.\n",
    "\n",
    "### One-vs-Rest (OvR) Classification\n",
    "\n",
    "The **One-vs-Rest (OvR)** strategy, also known as *one-against-all*, provides a straightforward and computationally efficient approach for extending binary classification algorithms to multi-class settings. Given a classification problem with $k$ distinct classes, OvR constructs $k$ binary classifiers, denoted by $h_1, h_2, \\dots, h_k$. Each classifier $h_i$ is trained to distinguish instances of class $i$ (treated as the positive class) from instances belonging to all other classes (treated as the negative class).\n",
    "\n",
    "Formally, for a training instance $(x, y)$, the $i$-th classifier is trained with labels:\n",
    "$$\n",
    "y_i = \\begin{cases}\n",
    "1 & \\text{if } y = i \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "During inference, all $k$ classifiers are evaluated on the test input $x$. Each classifier $h_i$ returns a score or confidence value, often interpreted as a probability $P(y = i \\mid x)$. The final predicted class is the one with the highest score:\n",
    "$$\n",
    "\\hat{y} = \\arg\\max_{i \\in \\{1, \\dots, k\\}} h_i(x)\n",
    "$$\n",
    "\n",
    "OvR has the advantage of requiring only $k$ classifiers, which scales linearly with the number of classes and is thus favorable for large-scale classification tasks. However, the main limitation of OvR lies in the **imbalance of class distributions** in each binary subproblem: each classifier sees only one class as positive and all others collapsed into a single negative category, which can skew the learning process, particularly when classes are imbalanced.\n",
    "\n",
    "\n",
    "### One-vs-One (OvO) Classification\n",
    "\n",
    "The **One-vs-One (OvO)** strategy, also known as *all-pairs* or *pairwise classification*, constructs a binary classifier for every pair of classes. Given $k$ classes, this yields:\n",
    "$$\n",
    "\\binom{k}{2} = \\frac{k(k-1)}{2}\n",
    "$$\n",
    "binary classifiers, each trained on a restricted subset of the data.\n",
    "\n",
    "More precisely, the classifier $h_{i,j}$ is trained to distinguish between class $i$ and class $j$ using only the examples $(x, y)$ such that $y \\in \\{i, j\\}$. All other instances are discarded during training of $h_{i,j}$. In prediction, each classifier casts a *vote* for one of the two classes:\n",
    "$$\n",
    "h_{i,j}(x) \\in \\{i, j\\}\n",
    "$$\n",
    "\n",
    "Once all $\\frac{k(k-1)}{2}$ classifiers have voted, the final prediction is made by majority rule:\n",
    "$$\n",
    "\\hat{y} = \\arg\\max_{i} \\sum_{j \\ne i} \\mathbf{1}\\{ h_{i,j}(x) = i \\}\n",
    "$$\n",
    "\n",
    "OvO has the advantage of **balanced binary classification tasks**, since each classifier is trained on data from only two classes. This often results in better empirical performance when the dataset suffers from class imbalance or when the classes are not linearly separable in the original space. However, the computational cost of training and evaluating $\\mathcal{O}(k^2)$ classifiers can become prohibitive as $k$ grows large.\n",
    "\n",
    "\n",
    "### Comparative Analysis\n",
    "\n",
    "We now summarize key distinctions between OvR and OvO classification strategies:\n",
    "\n",
    "| Criterion | One-vs-Rest (OvR) | One-vs-One (OvO) |\n",
    "|--|--|--|\n",
    "| Number of classifiers | $k$ | $\\frac{k(k-1)}{2}$ |\n",
    "| Training set size per classifier | Full dataset | Subset with two classes |\n",
    "| Training time | Lower | Higher |\n",
    "| Class imbalance handling | Less robust | More robust |\n",
    "| Memory usage | Low | Moderate to high |\n",
    "| Prediction cost | $k$ evaluations | $\\mathcal{O}(k^2)$ evaluations |\n",
    "| Preferred context | Large $k$, efficient training | Small $k$, balanced data |\n",
    "\n",
    "In practice, **OvR** is often favored in large-scale problems due to its lower computational cost and simpler model management. Frameworks such as logistic regression and support vector machines frequently rely on OvR for multi-class generalization. In contrast, **OvO** tends to perform better in tasks with a relatively small number of classes or where balanced binary decisions yield more stable classifiers.\n",
    "\n",
    "It is worth emphasizing that both OvR and OvO are **meta-strategies**: they do not prescribe a specific learning algorithm, but rather a structural decomposition of the multi-class problem. They can be combined with various base learners, such as decision trees, SVMs, or boosted models, and adapted to either bagging or boosting frameworks, depending on the design constraints and goals of the learning system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1e4485-02c9-4a98-9bcc-e1f8c58d3db1",
   "metadata": {},
   "source": [
    "## A Synthetic Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e799951-fdae-41d2-80db-55b6cb73e5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import load_iris, load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bbe66e-ab51-413a-b96d-889ec0690835",
   "metadata": {},
   "source": [
    "Below, I am going to generate a synthetic example to show differences between OvO and OvR classification schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "889b7750-e465-4bd5-ba0a-ef67c0c87f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=6,\n",
    "                           n_classes=4, n_clusters_per_class=1)\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Base model\n",
    "base_model = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c7c8a2-d358-43f8-bf6f-42b68f67cd50",
   "metadata": {},
   "source": [
    "Now, let us implement OvO and OvR strategies and apply it to our base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c04557a3-16b8-4aae-a427-64fc94ae5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-vs-Rest\n",
    "ovr_model = OneVsRestClassifier(base_model)\n",
    "ovr_model.fit(X_train, y_train)\n",
    "y_pred_ovr = ovr_model.predict(X_test)\n",
    "acc_ovr = accuracy_score(y_test, y_pred_ovr)\n",
    "conf_ovr = confusion_matrix(y_test, y_pred_ovr)\n",
    "\n",
    "# One-vs-One\n",
    "ovo_model = OneVsOneClassifier(base_model)\n",
    "ovo_model.fit(X_train, y_train)\n",
    "y_pred_ovo = ovo_model.predict(X_test)\n",
    "acc_ovo = accuracy_score(y_test, y_pred_ovo)\n",
    "conf_ovo = confusion_matrix(y_test, y_pred_ovo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b692b70-e8f7-4904-8a4a-a6e6844d2112",
   "metadata": {},
   "source": [
    "Here are the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f74024fb-613c-408c-b558-85af83965fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "sns.heatmap(conf_ovr, annot=True, fmt='d', cmap=\"Blues\", ax=axes[0], cbar=False)\n",
    "axes[0].set_title(f\"One-vs-Rest (OvR)\\nAccuracy: {acc_ovr:.2f}\")\n",
    "axes[0].set_xlabel(\"Predicted Label\")\n",
    "axes[0].set_ylabel(\"True Label\")\n",
    "\n",
    "sns.heatmap(conf_ovo, annot=True, fmt='d', cmap=\"Greens\", ax=axes[1], cbar=False)\n",
    "axes[1].set_title(f\"One-vs-One (OvO)\\nAccuracy: {acc_ovo:.2f}\")\n",
    "axes[1].set_xlabel(\"Predicted Label\")\n",
    "axes[1].set_ylabel(\"True Label\")\n",
    "\n",
    "plt.suptitle(\"Comparison of OvR and OvO Classification (Logistic Regression)\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088e42eb-805a-473a-9457-51b9c2c6c2b6",
   "metadata": {},
   "source": [
    "- **OvO achieved slightly higher accuracy (0.86)** compared to **OvR (0.82)**.  \n",
    "- The confusion matrices show **OvO makes fewer large misclassifications**, likely due to its more balanced training subsets.\n",
    "- **OvR trains only 4 classifiers**, while **OvO trains 6**, which is computationally more intensive but potentially more accurate.\n",
    "\n",
    "As you can see OvR is simpler and faster, appropriate when the number of classes is large. But OvO often provides better performance on small- to mid-scale multi-class problems, especially when binary distinctions are more separable than one-vs-all boundaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d0e721-4cd8-43bd-a821-dedbfba7efc9",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "**Random Forest** is a powerful ensemble learning method introduced by Leo Breiman, and remains one of the most widely used algorithms for both classification and regression tasks. It is an instance of the **bagging** (bootstrap aggregating) framework, but introduces additional randomization in feature selection, making it especially robust and effective.\n",
    "\n",
    "At its core, a random forest is an ensemble of **decision trees**, each trained on a different random subset of the training data. The final prediction is obtained by **aggregating the predictions** of all trees in the ensemblevia **majority voting** for classification, or **averaging** for regression:\n",
    "$$\n",
    "\\hat{y}_{\\text{RF}}(x) = \\frac{1}{T} \\sum_{t=1}^T h_t(x)\n",
    "$$\n",
    "where $h_t$ is the $t$-th tree in the ensemble.\n",
    "\n",
    "### Training Procedure\n",
    "\n",
    "Random Forest builds each tree using two layers of randomness:\n",
    "\n",
    "1. **Bootstrap Sampling**: Each tree is trained on a bootstrap sample $\\mathcal{D}_t$ drawn from the original dataset $\\mathcal{D}$ with replacement. This introduces variation in training data across trees.\n",
    "\n",
    "2. **Random Feature Selection**: At each node of the decision tree, a random subset of features of fixed size $m \\ll p$ (where $p$ is the total number of features) is selected, and the split is chosen only among those features.\n",
    "\n",
    "This process yields a collection of **decorrelated trees**, each with high variance but low bias. Aggregating these predictions significantly **reduces variance**, yielding a more stable and generalizable model.\n",
    "\n",
    "\n",
    "### Motivation and Theoretical Justification\n",
    "\n",
    "Random Forests operate under the principle that averaging multiple uncorrelated models reduces overall variance. More formally, if $\\text{Var}(h_t(x)) = \\sigma^2$ and the pairwise correlation between any two trees is $\\rho$, then the variance of the aggregated forest predictor is:\n",
    "$$\n",
    "\\text{Var}(\\hat{y}_{\\text{RF}}(x)) = \\rho \\sigma^2 + \\frac{1 - \\rho}{T} \\sigma^2\n",
    "$$\n",
    "As $T \\to \\infty$, the second term vanishes, and the ensemble variance converges to $\\rho \\sigma^2$. Hence, minimizing the correlation $\\rho$ between trees is crucial, which is precisely what the random feature subspace selection achieves.\n",
    "\n",
    "\n",
    "### Comparison to Standard Bagging\n",
    "\n",
    "Standard bagging (as applied to decision trees) reduces variance by averaging across multiple high-variance estimators. However, if the base learners are highly correlated (e.g., because all trees greedily split on the same dominant features), baggings variance reduction is limited. Random Forest mitigates this by **injecting feature randomness**, ensuring that different trees explore different partitions of the input space.\n",
    "\n",
    "Thus, Random Forest is best seen as **decorrelated bagging**, combining the strengths of tree ensembles with effective variance reduction.\n",
    "\n",
    "\n",
    "### Properties and Advantages\n",
    "\n",
    "- **Robustness**: Performs well on high-dimensional data and in the presence of noise.\n",
    "- **Non-parametric**: No assumptions on the underlying data distribution.\n",
    "- **Feature Importance**: Can provide estimates of feature relevance via mean decrease in impurity or permutation importance.\n",
    "- **Out-of-Bag Estimation**: Offers an unbiased estimate of generalization error using samples not included in the bootstrap training set.\n",
    "\n",
    "\n",
    "### Practical Considerations\n",
    "\n",
    "Key hyperparameters in Random Forest include:\n",
    "- `n_estimators`: the number of trees in the forest.\n",
    "- `max_features`: the number of features considered at each split (commonly $\\sqrt{p}$ for classification, $p/3$ for regression).\n",
    "- `max_depth`, `min_samples_split`, `min_samples_leaf`: to control individual tree complexity and prevent overfitting.\n",
    "- `bootstrap`: whether to use bootstrap sampling (can be turned off for subsampling).\n",
    "\n",
    "Random Forest often serves as a **strong baseline** in practical machine learning workflows and is especially valuable in tabular data tasks, offering high accuracy, interpretability, and resistance to overfitting.\n",
    "\n",
    "\n",
    "For a theoretical introduction, see *L. Breiman, Random Forests, Machine Learning, vol. 45, no. 1, pp. 532, 2001.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "107993a7-318a-4712-8223-657cc59475d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(X,y,strategy,model,test=0.25):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test)\n",
    "    res = strategy(model).fit(X_train, y_train)\n",
    "    y_pred = res.predict(X_test)\n",
    "    return classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eff095-35d2-4ccc-85b0-eb7933074ba0",
   "metadata": {},
   "source": [
    "### IRIS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e63bf94e-af3f-44cd-b418-2b53e8f9d2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "iris_X = iris.data\n",
    "iris_y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2a3a7d6-69f8-4741-856f-2729b9d9dd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       0.86      1.00      0.92        12\n",
      "           2       1.00      0.85      0.92        13\n",
      "\n",
      "    accuracy                           0.95        38\n",
      "   macro avg       0.95      0.95      0.95        38\n",
      "weighted avg       0.95      0.95      0.95        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(experiment(iris_X, iris_y,OneVsRestClassifier,RandomForestClassifier(n_estimators=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "017c2139-f403-4c50-b31f-b3bace754452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       0.79      1.00      0.88        11\n",
      "           2       1.00      0.79      0.88        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.93      0.93      0.92        38\n",
      "weighted avg       0.94      0.92      0.92        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(experiment(iris_X, iris_y,OneVsOneClassifier,RandomForestClassifier(n_estimators=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97997c92-89d5-4c9b-a5df-a3c35608f02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.80      0.80      0.80        10\n",
      "           2       0.86      0.86      0.86        14\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.89      0.89      0.89        38\n",
      "weighted avg       0.89      0.89      0.89        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(experiment(iris_X, iris_y,OneVsRestClassifier,LogisticRegression(max_iter=3000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8fb6a67-801a-4208-b1c6-39b321831f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      0.94      0.94        16\n",
      "           2       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.95        38\n",
      "   macro avg       0.96      0.96      0.96        38\n",
      "weighted avg       0.95      0.95      0.95        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(experiment(iris_X, iris_y, OneVsOneClassifier, SVC()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d848be-00f7-410f-ae1b-2d020148695e",
   "metadata": {},
   "source": [
    "### Digits Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2fee0d8-af5b-4798-bd29-e45fbaef3b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "digits_X = digits.data\n",
    "digits_y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1d89b4a-8418-4847-9429-7649f7a8c782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        41\n",
      "           1       0.93      0.97      0.95        39\n",
      "           2       1.00      1.00      1.00        57\n",
      "           3       1.00      0.90      0.95        49\n",
      "           4       1.00      0.98      0.99        48\n",
      "           5       0.95      0.98      0.96        55\n",
      "           6       0.98      1.00      0.99        46\n",
      "           7       0.98      1.00      0.99        43\n",
      "           8       0.83      0.91      0.87        33\n",
      "           9       0.94      0.85      0.89        39\n",
      "\n",
      "    accuracy                           0.96       450\n",
      "   macro avg       0.96      0.96      0.96       450\n",
      "weighted avg       0.96      0.96      0.96       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(experiment(digits_X, digits_y, OneVsRestClassifier, RandomForestClassifier(n_estimators=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b4ebb8a-38b1-4c11-aadd-3b56bb27c86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        45\n",
      "           1       0.93      0.95      0.94        44\n",
      "           2       1.00      1.00      1.00        53\n",
      "           3       0.95      0.91      0.93        46\n",
      "           4       1.00      1.00      1.00        41\n",
      "           5       0.94      0.98      0.96        61\n",
      "           6       0.98      1.00      0.99        43\n",
      "           7       1.00      0.95      0.97        40\n",
      "           8       0.85      0.89      0.87        37\n",
      "           9       0.97      0.90      0.94        40\n",
      "\n",
      "    accuracy                           0.96       450\n",
      "   macro avg       0.96      0.96      0.96       450\n",
      "weighted avg       0.96      0.96      0.96       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(experiment(digits_X, digits_y, OneVsRestClassifier, LogisticRegression(max_iter=4000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d5d9483-1f6e-436d-af0a-550b37d086d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.98      1.00      0.99        42\n",
      "           2       1.00      1.00      1.00        53\n",
      "           3       0.98      0.98      0.98        50\n",
      "           4       1.00      0.98      0.99        41\n",
      "           5       0.94      0.97      0.96        34\n",
      "           6       0.98      1.00      0.99        46\n",
      "           7       1.00      0.98      0.99        46\n",
      "           8       0.95      0.98      0.97        43\n",
      "           9       0.98      0.93      0.95        45\n",
      "\n",
      "    accuracy                           0.98       450\n",
      "   macro avg       0.98      0.98      0.98       450\n",
      "weighted avg       0.98      0.98      0.98       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(experiment(digits_X, digits_y, OneVsOneClassifier, SVC()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84676967-c0de-4a82-a0c1-d27e4875fc13",
   "metadata": {},
   "source": [
    "## AdaBoost\n",
    "\n",
    "**AdaBoost** (short for *Adaptive Boosting*) is a sequential ensemble learning algorithm that constructs a strong classifier by linearly combining multiple **weak learners**, each of which performs only slightly better than random guessing. The key idea behind AdaBoost is to iteratively train a sequence of models, where each model focuses increasingly on the training instances that were misclassified by its predecessors.\n",
    "\n",
    "In each round, AdaBoost adjusts the weights of the training examples: examples that were misclassified by the previous model are given higher weight, making them more influential in the next round. After a fixed number of rounds (or until convergence), the final classifier is constructed as a **weighted majority vote** of the individual weak learners.\n",
    "\n",
    "AdaBoost adaptively re-weights the training data to focus successive learners on the hardest examples. It transforms weak learners into a highly accurate ensemble by minimizing an exponential loss function and can be interpreted as performing **functional gradient descent in function space**.\n",
    "\n",
    "Despite its simplicity, AdaBoost remains a foundational method in ensemble learning, and many modern boosting algorithms (e.g., Gradient Boosting, XGBoost) are generalizations of its core ideas.\n",
    "\n",
    "### Training Procedure\n",
    "\n",
    "AdaBoost proceeds in $T$ boosting rounds. Let the training dataset be $\\{(x_i, y_i)\\}_{i=1}^n$ with labels $y_i \\in \\{-1, +1\\}$.\n",
    "\n",
    "1. **Initialization**: Assign uniform weights to each data point:\n",
    "   $$\n",
    "   D_1(i) = \\frac{1}{n} \\quad \\text{for all } i = 1, \\dots, n\n",
    "   $$\n",
    "\n",
    "2. **Iterative Training** (for $t = 1$ to $T$):\n",
    "\n",
    "   - Train a weak learner $h_t(x)$ on the weighted training data $D_t$.\n",
    "   - Compute the weighted error of $h_t$:\n",
    "     $$\n",
    "     \\varepsilon_t = \\sum_{i=1}^n D_t(i) \\cdot \\mathbf{1}\\left\\{ h_t(x_i) \\ne y_i \\right\\}\n",
    "     $$\n",
    "   - Compute the **boosting coefficient** (or model weight):\n",
    "     $$\n",
    "     \\alpha_t = \\frac{1}{2} \\log\\left( \\frac{1 - \\varepsilon_t}{\\varepsilon_t} \\right)\n",
    "     $$\n",
    "   - Update the weights for the next round:\n",
    "     $$\n",
    "     D_{t+1}(i) = \\frac{D_t(i) \\cdot e^{-\\alpha_t y_i h_t(x_i)}}{Z_t}\n",
    "     $$\n",
    "     where $Z_t$ is a normalization constant ensuring $\\sum_i D_{t+1}(i) = 1$.\n",
    "\n",
    "This update rule **increases the weight** of misclassified points and **decreases the weight** of correctly classified ones, thus directing the attention of future learners toward more difficult cases.\n",
    "\n",
    "\n",
    "### Final Prediction\n",
    "\n",
    "After $T$ iterations, the final classifier is given by:\n",
    "$$\n",
    "H(x) = \\text{sign} \\left( \\sum_{t=1}^T \\alpha_t h_t(x) \\right)\n",
    "$$\n",
    "\n",
    "This is a **weighted majority vote**, where each learner's vote is scaled by its confidence $\\alpha_t$. Learners with higher accuracy have a greater influence on the ensemble decision.\n",
    "\n",
    "### Choice of Base Learner\n",
    "\n",
    "Although AdaBoost can, in theory, use any weak learner, it is most commonly used with **decision stumps**decision trees with depth 1. These stumps are computationally efficient, less prone to overfitting, and align well with AdaBoost's theoretical foundations, which assume the base learner minimizes weighted classification error.\n",
    "\n",
    "### Binary vs Multi-Class Classification\n",
    "\n",
    "Originally formulated for binary classification, AdaBoost has been extended to multi-class settings via strategies such as:\n",
    "\n",
    "- **One-vs-Rest (OvR)**: Train $k$ binary AdaBoost classifiers, each distinguishing one class against the rest.\n",
    "- **One-vs-One (OvO)**: Train $\\frac{k(k-1)}{2}$ pairwise classifiers.\n",
    "- **SAMME and SAMME.R** algorithms**: Direct generalizations of AdaBoost for multi-class settings without needing decomposition into binary subproblems.\n",
    "\n",
    "In binary classification, the final prediction can also be interpreted probabilistically via:\n",
    "$$\n",
    "P(y = +1 \\mid x) \\approx \\frac{1}{1 + e^{-2F(x)}}, \\quad \\text{where } F(x) = \\sum_t \\alpha_t h_t(x)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3296914-12c3-4840-b226-5f7882493a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.92      0.92      0.92        12\n",
      "           2       0.91      0.91      0.91        11\n",
      "\n",
      "    accuracy                           0.95        38\n",
      "   macro avg       0.94      0.94      0.94        38\n",
      "weighted avg       0.95      0.95      0.95        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(experiment(iris_X,iris_y,OneVsOneClassifier,AdaBoostClassifier(estimator=LogisticRegression(max_iter=2000)),test=0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7494e3b0-fe53-4906-91f9-d7dbdc80be6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        37\n",
      "           1       0.91      0.98      0.94        42\n",
      "           2       1.00      1.00      1.00        55\n",
      "           3       0.98      0.90      0.94        49\n",
      "           4       0.98      0.93      0.95        43\n",
      "           5       0.90      0.95      0.93        40\n",
      "           6       1.00      1.00      1.00        47\n",
      "           7       0.94      1.00      0.97        50\n",
      "           8       0.93      0.93      0.93        43\n",
      "           9       0.98      0.93      0.95        44\n",
      "\n",
      "    accuracy                           0.96       450\n",
      "   macro avg       0.96      0.96      0.96       450\n",
      "weighted avg       0.96      0.96      0.96       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(experiment(digits_X, digits_y, OneVsOneClassifier, AdaBoostClassifier(),test=0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54cad021-c549-4b63-8537-9bfae3f6514e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        41\n",
      "           1       0.96      0.96      0.96        50\n",
      "           2       1.00      0.98      0.99        45\n",
      "           3       0.94      0.87      0.91        39\n",
      "           4       0.98      0.98      0.98        48\n",
      "           5       0.95      0.98      0.96        53\n",
      "           6       0.98      1.00      0.99        50\n",
      "           7       0.97      1.00      0.99        39\n",
      "           8       0.93      0.88      0.90        43\n",
      "           9       0.93      0.98      0.95        42\n",
      "\n",
      "    accuracy                           0.96       450\n",
      "   macro avg       0.96      0.96      0.96       450\n",
      "weighted avg       0.96      0.96      0.96       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(experiment(digits_X, digits_y, OneVsOneClassifier, AdaBoostClassifier(),test=0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65ac63d9-aead-4b6e-94e3-1bed3e099c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        44\n",
      "           1       0.00      0.00      0.00        54\n",
      "           2       0.00      0.00      0.00        51\n",
      "           3       0.00      0.00      0.00        38\n",
      "           4       0.00      0.00      0.00        46\n",
      "           5       0.00      0.00      0.00        47\n",
      "           6       0.10      1.00      0.17        43\n",
      "           7       0.00      0.00      0.00        45\n",
      "           8       0.00      0.00      0.00        43\n",
      "           9       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.10       450\n",
      "   macro avg       0.01      0.10      0.02       450\n",
      "weighted avg       0.01      0.10      0.02       450\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaygun/.local/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kaygun/.local/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kaygun/.local/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(experiment(digits_X, digits_y, OneVsRestClassifier, AdaBoostClassifier(estimator=SVC(max_iter=2000, probability=True)),test=0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36847023-638b-4eb3-a0fb-a4f783f93f60",
   "metadata": {},
   "source": [
    "## LightGBM\n",
    "\n",
    "**LightGBM** (Light Gradient Boosting Machine) is a gradient boosting framework designed for **efficiency, scalability, and high predictive accuracy**. It builds an ensemble of decision trees in a sequential manner, where each tree is trained to minimize the residual errors (i.e., the gradient of the loss function) of the current model. This is conceptually rooted in **functional gradient descent** and generalizes the ideas underlying AdaBoost and traditional boosting algorithms.\n",
    "\n",
    "Formally, given a training dataset $\\{(x_i, y_i)\\}_{i=1}^n$ and a differentiable loss function $\\mathcal{L}(y, \\hat{y})$, the model seeks to minimize the empirical risk:\n",
    "$$\n",
    "\\min_{F} \\sum_{i=1}^n \\mathcal{L}(y_i, F(x_i))\n",
    "$$\n",
    "LightGBM constructs $F(x)$ as an additive model:\n",
    "$$\n",
    "F(x) = \\sum_{t=1}^T f_t(x), \\quad f_t \\in \\mathcal{H}\n",
    "$$\n",
    "where each $f_t$ is a decision tree (from a function class $\\mathcal{H}$), and each iteration adds a new tree $f_t$ trained to fit the **negative gradient** of the loss at the current step.\n",
    "\n",
    "\n",
    "### Histogram-based Split Finding\n",
    "\n",
    "One of the most distinguishing features of LightGBM is its **histogram-based algorithm** for constructing decision trees. Instead of evaluating all possible split points, LightGBM first discretizes continuous features into $k$ bins (usually $k = 255$ by default). Then, for each bin, it computes histograms of gradient statistics (first- and second-order derivatives of the loss), and uses these summaries to find the best approximate split.\n",
    "\n",
    "This binning strategy:\n",
    "\n",
    "- Reduces memory usage (no need to sort or store all feature values),\n",
    "- Speeds up computation (faster split finding),\n",
    "- Naturally supports **categorical features** without the need for one-hot encoding or manual transformation.\n",
    "\n",
    "\n",
    "### Leaf-wise Tree Growth\n",
    "\n",
    "Unlike traditional level-wise algorithms (e.g., XGBoost), which expand the tree layer-by-layer, LightGBM employs a **leaf-wise tree growth strategy**. At each step, the algorithm chooses the leaf that yields the greatest reduction in loss and splits it. This greedy approach leads to **asymmetrical trees** that are deeper on paths with higher potential for gain:\n",
    "$$\n",
    "\\text{split leaf } \\ell^* = \\arg\\max_{\\ell} \\text{gain}(\\ell)\n",
    "$$\n",
    "\n",
    "While this strategy tends to improve accuracy by focusing modeling capacity where needed, it can also lead to **overfitting** if not carefully regularized.\n",
    "\n",
    "\n",
    "### Gradient-Based Optimization\n",
    "\n",
    "At each boosting round, LightGBM fits the new tree to approximate the negative gradient of the loss with respect to the model's output:\n",
    "$$\n",
    "g_i^{(t)} = -\\frac{\\partial \\mathcal{L}(y_i, F^{(t-1)}(x_i))}{\\partial F}, \\quad\n",
    "h_i^{(t)} = \\frac{\\partial^2 \\mathcal{L}(y_i, F^{(t-1)}(x_i))}{\\partial F^2}\n",
    "$$\n",
    "\n",
    "It uses both the **first-order** and **second-order** statistics (similar to Newton-Raphson updates) to guide the split decisions and tree structure. This supports efficient minimization of complex loss functions and facilitates custom objectives.\n",
    "\n",
    "\n",
    "### Parallel and Distributed Training\n",
    "\n",
    "LightGBM is designed with **scalability** in mind. It supports:\n",
    "- **Multi-threaded CPU training** using feature-parallel and data-parallel strategies,\n",
    "- **Distributed learning** on large datasets using frameworks like **MPI** and **Apache Spark**,\n",
    "- **Out-of-core learning** to train on datasets that exceed memory limits.\n",
    "\n",
    "Its histogram-based compression and support for **exclusive feature bundling (EFB)** further reduce the computational burden, especially on high-dimensional sparse datasets.\n",
    "\n",
    "\n",
    "### Regularization and Control\n",
    "\n",
    "To prevent overfitting and control tree complexity, LightGBM provides a range of **regularization parameters**:\n",
    "\n",
    "- `max_depth`: maximum depth of any tree (controls model capacity),\n",
    "- `min_child_samples`: minimum number of samples required in a leaf (analogous to pruning),\n",
    "- `lambda_l2`: L2 regularization on leaf scores (shrinkage),\n",
    "- `feature_fraction`, `bagging_fraction`: analogous to dropout in neural networks.\n",
    "\n",
    "Tuning these hyperparameters is essential for ensuring generalization, especially when using large trees or many boosting iterations.\n",
    "\n",
    "-\n",
    "### Use Cases and Practical Relevance\n",
    "\n",
    "LightGBM is frequently the algorithm of choice in:\n",
    "- **Large-scale machine learning competitions** (e.g., Kaggle),\n",
    "- **Production systems** where inference speed and memory footprint matter,\n",
    "- Problems involving **sparse, high-dimensional** features (e.g., CTR prediction, NLP embeddings).\n",
    "\n",
    "Its flexibility, support for custom losses, and rich hyperparameter interface make it one of the most powerful tools in modern applied machine learning. For more details on tuning strategies, feature handling, and distributed training, consult the [official LightGBM documentation](https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33a9792a-0d66-46f0-804d-79124a765ba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 140, number of negative: 1207\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 830\n",
      "[LightGBM] [Info] Number of data points in the train set: 1347, number of used features: 53\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.103935 -> initscore=-2.154251\n",
      "[LightGBM] [Info] Start training from score -2.154251\n",
      "[LightGBM] [Info] Number of positive: 137, number of negative: 1210\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 830\n",
      "[LightGBM] [Info] Number of data points in the train set: 1347, number of used features: 53\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101707 -> initscore=-2.178395\n",
      "[LightGBM] [Info] Start training from score -2.178395\n",
      "[LightGBM] [Info] Number of positive: 134, number of negative: 1213\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 830\n",
      "[LightGBM] [Info] Number of data points in the train set: 1347, number of used features: 53\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099480 -> initscore=-2.203012\n",
      "[LightGBM] [Info] Start training from score -2.203012\n",
      "[LightGBM] [Info] Number of positive: 136, number of negative: 1211\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 830\n",
      "[LightGBM] [Info] Number of data points in the train set: 1347, number of used features: 53\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100965 -> initscore=-2.186547\n",
      "[LightGBM] [Info] Start training from score -2.186547\n",
      "[LightGBM] [Info] Number of positive: 121, number of negative: 1226\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000320 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 830\n",
      "[LightGBM] [Info] Number of data points in the train set: 1347, number of used features: 53\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.089829 -> initscore=-2.315722\n",
      "[LightGBM] [Info] Start training from score -2.315722\n",
      "[LightGBM] [Info] Number of positive: 150, number of negative: 1197\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 830\n",
      "[LightGBM] [Info] Number of data points in the train set: 1347, number of used features: 53\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.111359 -> initscore=-2.076938\n",
      "[LightGBM] [Info] Start training from score -2.076938\n",
      "[LightGBM] [Info] Number of positive: 127, number of negative: 1220\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 830\n",
      "[LightGBM] [Info] Number of data points in the train set: 1347, number of used features: 53\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.094284 -> initscore=-2.262419\n",
      "[LightGBM] [Info] Start training from score -2.262419\n",
      "[LightGBM] [Info] Number of positive: 133, number of negative: 1214\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 830\n",
      "[LightGBM] [Info] Number of data points in the train set: 1347, number of used features: 53\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.098738 -> initscore=-2.211327\n",
      "[LightGBM] [Info] Start training from score -2.211327\n",
      "[LightGBM] [Info] Number of positive: 124, number of negative: 1223\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001059 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 830\n",
      "[LightGBM] [Info] Number of data points in the train set: 1347, number of used features: 53\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.092056 -> initscore=-2.288781\n",
      "[LightGBM] [Info] Start training from score -2.288781\n",
      "[LightGBM] [Info] Number of positive: 145, number of negative: 1202\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 830\n",
      "[LightGBM] [Info] Number of data points in the train set: 1347, number of used features: 53\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.107647 -> initscore=-2.115008\n",
      "[LightGBM] [Info] Start training from score -2.115008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        38\n",
      "           1       0.96      0.98      0.97        45\n",
      "           2       1.00      0.95      0.98        43\n",
      "           3       0.91      0.91      0.91        47\n",
      "           4       1.00      1.00      1.00        60\n",
      "           5       0.86      1.00      0.93        32\n",
      "           6       1.00      0.94      0.97        54\n",
      "           7       0.96      1.00      0.98        46\n",
      "           8       1.00      0.96      0.98        50\n",
      "           9       0.97      0.89      0.93        35\n",
      "\n",
      "    accuracy                           0.96       450\n",
      "   macro avg       0.96      0.96      0.96       450\n",
      "weighted avg       0.96      0.96      0.96       450\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaygun/.local/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/kaygun/.local/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/kaygun/.local/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/kaygun/.local/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/kaygun/.local/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/kaygun/.local/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/kaygun/.local/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/kaygun/.local/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/kaygun/.local/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/kaygun/.local/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(experiment(digits_X, digits_y, OneVsRestClassifier, LGBMClassifier(num_leaves=10, n_estimators=50),test=0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54f33ef-7111-4bbe-a326-37951fff483b",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "**XGBoost** (short for *Extreme Gradient Boosting*) is a scalable, highly optimized implementation of gradient boosting that has become a state-of-the-art tool for supervised learning tasks. It is particularly effective in regression, classification, and ranking problems, and has been a consistent top-performer in machine learning competitions such as Kaggle.\n",
    "\n",
    "At its core, XGBoost constructs an additive model of decision trees, each trained to correct the residual errors of the current ensemble. Like other boosting algorithms, it builds the predictor $F(x)$ in a stage-wise fashion:\n",
    "$$\n",
    "F^{(t)}(x) = F^{(t-1)}(x) + f_t(x), \\quad f_t \\in \\mathcal{H}\n",
    "$$\n",
    "where $\\mathcal{H}$ is the space of decision trees.\n",
    "\n",
    "\n",
    "\n",
    "### Regularized Objective Function\n",
    "\n",
    "Unlike traditional gradient boosting, XGBoost explicitly optimizes a **regularized objective function**:\n",
    "$$\n",
    "\\mathcal{L}^{(t)} = \\sum_{i=1}^n \\ell(y_i, \\hat{y}_i^{(t)}) + \\sum_{t=1}^T \\Omega(f_t)\n",
    "$$\n",
    "\n",
    "The **loss function** $\\ell(y, \\hat{y})$ measures the prediction error (e.g., squared loss, logistic loss), and the **regularization term** $\\Omega(f)$ penalizes model complexity:\n",
    "$$\n",
    "\\Omega(f) = \\gamma T + \\frac{1}{2} \\lambda \\sum_{j=1}^T w_j^2\n",
    "$$\n",
    "where:\n",
    "- $T$ is the number of leaves in the tree,\n",
    "- $w_j$ is the score (weight) assigned to leaf $j$,\n",
    "- $\\gamma$ and $\\lambda$ are hyperparameters controlling regularization.\n",
    "\n",
    "This regularization encourages **smaller trees with smoother outputs**, improving generalization and reducing overfitting.\n",
    "\n",
    "\n",
    "\n",
    "### Second-Order Approximation\n",
    "\n",
    "At each iteration, XGBoost performs a **second-order Taylor expansion** of the loss:\n",
    "$$\n",
    "\\ell(y_i, F^{(t-1)}(x_i) + f(x_i)) \\approx \\ell(y_i, F^{(t-1)}(x_i)) + g_i f(x_i) + \\frac{1}{2} h_i f(x_i)^2\n",
    "$$\n",
    "where:\n",
    "- $g_i = \\frac{\\partial \\ell}{\\partial \\hat{y}_i}$ is the first-order gradient,\n",
    "- $h_i = \\frac{\\partial^2 \\ell}{\\partial \\hat{y}_i^2}$ is the second-order derivative (Hessian).\n",
    "\n",
    "XGBoost then selects $f_t(x)$ (i.e., the next tree) to minimize this approximation of the loss plus regularization.\n",
    "\n",
    "\n",
    "\n",
    "### Split Finding and Gain\n",
    "\n",
    "For each candidate split in the tree, XGBoost computes the **gain** in the regularized loss. For a node split into left and right children:\n",
    "$$\n",
    "\\text{Gain} = \\frac{1}{2} \\left[ \\frac{G_L^2}{H_L + \\lambda} + \\frac{G_R^2}{H_R + \\lambda} - \\frac{(G_L + G_R)^2}{H_L + H_R + \\lambda} \\right] - \\gamma\n",
    "$$\n",
    "where $G$ and $H$ are sums of gradients and Hessians over the respective child nodes. The best split maximizes this gain.\n",
    "\n",
    "This **greedy, gain-maximizing tree construction** is repeated until stopping criteria such as `max_depth` or minimum gain are met.\n",
    "\n",
    "\n",
    "\n",
    "### Notable Features\n",
    "\n",
    "- **Built-in Regularization**:\n",
    "  Controls model complexity via `gamma`, `lambda`, `min_child_weight`, and tree-specific parameters (`max_depth`, `subsample`).\n",
    "\n",
    "- **Parallelized Tree Construction**:\n",
    "  XGBoost partitions data into blocks and computes histogram-based splits in parallel across threads.\n",
    "\n",
    "- **Missing Value Handling**:\n",
    "  Missing feature values are handled natively: for each split, XGBoost learns the **default direction** (left or right) that minimizes loss when a feature is missing.\n",
    "\n",
    "- **Sparsity-Aware Learning**:\n",
    "  Efficient for datasets with missing or sparse inputs (common in NLP or recommender systems).\n",
    "\n",
    "- **Extensibility**:\n",
    "  Supports custom loss functions, ranking objectives, monotonic constraints, and more.\n",
    "\n",
    "\n",
    "\n",
    "### Comparison with Other Boosting Methods\n",
    "\n",
    "| Aspect | XGBoost | LightGBM | AdaBoost |\n",
    "|---|---|---|---|\n",
    "| Tree Growth | Level-wise | Leaf-wise | Level-wise |\n",
    "| Objective | Second-order w/ regularization | First/second-order | Exponential loss |\n",
    "| Regularization | Explicit (L1/L2) | Implicit | None (original) |\n",
    "| Speed | High, but slower than LGBM | Extremely fast | Fast |\n",
    "| Feature Support | Sparse-aware, missing values | Native categorical support | Requires preprocessing |\n",
    "| Use Case | Tabular, structured data | Large-scale/tabular | Simpler problems |\n",
    "\n",
    "\n",
    "### Practical Notes\n",
    "\n",
    "Key hyperparameters to tune include:\n",
    "\n",
    "- `eta`: learning rate (shrinkage factor),\n",
    "- `max_depth`, `min_child_weight`: control tree complexity,\n",
    "- `gamma`: minimum loss reduction to make a split,\n",
    "- `subsample`, `colsample_bytree`: stochastic sampling,\n",
    "- `lambda`, `alpha`: L2 and L1 regularization weights.\n",
    "\n",
    "XGBoosts **robust generalization**, **strong theoretical motivation**, and **implementation efficiency** have made it a cornerstone in industrial ML pipelines and competitive data science.\n",
    "\n",
    "For further details, see the [XGBoost documentation](https://xgboost.readthedocs.io/en/latest/) or Tianqi Chen & Carlos Guestrin, XGBoost: A Scalable Tree Boosting System, *KDD 2016*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39fd7fed-a7ef-4df5-b299-d6ce3af23105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experimentXG(X,y,num_classes,rounds=50,test=0.25):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test)\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "    params = {\n",
    "        'objective': 'multi:softmax',  # Multiclass classification objective\n",
    "        'num_class': num_classes,  # Number of classes in the dataset\n",
    "        'eval_metric': 'merror'  # Evaluation metric: multiclass classification error rate\n",
    "    }\n",
    "    model = xgb.train(params, dtrain, rounds)\n",
    "    y_pred = model.predict(dtest)\n",
    "    \n",
    "    return classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d69f4f16-c191-40b0-94b2-08cb70dd9360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95        41\n",
      "           1       0.94      0.94      0.94        53\n",
      "           2       0.96      0.93      0.95        46\n",
      "           3       0.92      0.94      0.93        52\n",
      "           4       0.97      1.00      0.99        39\n",
      "           5       0.98      0.94      0.96        48\n",
      "           6       1.00      0.97      0.99        40\n",
      "           7       0.95      0.98      0.96        42\n",
      "           8       0.95      0.95      0.95        43\n",
      "           9       0.96      0.93      0.95        46\n",
      "\n",
      "    accuracy                           0.96       450\n",
      "   macro avg       0.96      0.96      0.96       450\n",
      "weighted avg       0.96      0.96      0.96       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(experimentXG(digits_X,digits_y,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6fa98988-23a6-4486-b6cf-68ecb38c8e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        38\n",
      "   macro avg       1.00      1.00      1.00        38\n",
      "weighted avg       1.00      1.00      1.00        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(experimentXG(iris_X,iris_y,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e67fd4-15d0-45f8-b5e2-292eee6d344d",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "\n",
    "Let $f \\colon \\Omega \\subseteq \\mathbb{R}^n \\to \\mathbb{R}$ be a differentiable function defined on a compact set $\\Omega$. In machine learning, $f$ typically represents a **loss**, **risk**, or **penalty function**, and our goal is to find a minimizer:\n",
    "$$\n",
    "x^* = \\arg\\min_{x \\in \\Omega} f(x)\n",
    "$$\n",
    "\n",
    "The process of training a machine learning model is, in essence, a high-dimensional optimization problem where we adjust model parameters (e.g., weights $\\theta \\in \\mathbb{R}^d$) to minimize the empirical risk or loss over training data.\n",
    "\n",
    "The following are commonly used **iterative optimization algorithms** designed to efficiently solve this minimization problem, especially when $\\nabla f$ is known or can be estimated.\n",
    "\n",
    "\n",
    "\n",
    "### 1. **Gradient Descent (GD)**\n",
    "\n",
    "The most fundamental first-order method, **gradient descent**, iteratively updates parameters using the negative gradient of the objective:\n",
    "$$\n",
    "x_{k+1} = x_k - \\eta \\nabla f(x_k)\n",
    "$$\n",
    "where $\\eta > 0$ is the **learning rate** (step size). Under convexity and Lipschitz continuity of $\\nabla f$, gradient descent converges to a global minimum with rate $\\mathcal{O}(1/k)$.\n",
    "\n",
    "#### Variants:\n",
    "\n",
    "- **Stochastic Gradient Descent (SGD)**:\n",
    "  Uses an unbiased estimate $\\tilde{\\nabla} f(x_k)$ based on a single data point:\n",
    "  $$\n",
    "  x_{k+1} = x_k - \\eta \\tilde{\\nabla} f(x_k)\n",
    "  $$\n",
    "  It introduces variance, but is computationally efficient and suitable for large-scale problems.\n",
    "\n",
    "- **Mini-batch Gradient Descent**:\n",
    "  Estimates gradient using a mini-batch of size $m \\ll n$, offering a balance between computational cost and variance.\n",
    "\n",
    "\n",
    "\n",
    "### 2. **Adagrad (Adaptive Gradient Algorithm)**\n",
    "\n",
    "Adagrad adapts the learning rate for each parameter based on the historical squared gradients:\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{G_t + \\epsilon}} \\cdot \\nabla f(\\theta_t)\n",
    "$$\n",
    "where $G_t$ is a diagonal matrix with entries $G_{t,ii} = \\sum_{\\tau=1}^t (\\nabla f_i(\\theta_\\tau))^2$.\n",
    "\n",
    "- Advantage: Effective for sparse data and non-uniform feature scaling.\n",
    "- Limitation: The accumulated gradient causes learning rate to decay to zero.\n",
    "\n",
    "\n",
    "\n",
    "### 3. **AdaDelta**\n",
    "\n",
    "AdaDelta is an extension of Adagrad that resolves the learning rate decay issue by using exponentially decaying averages:\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - \\frac{\\sqrt{E[\\Delta \\theta^2]_t + \\epsilon}}{\\sqrt{E[g^2]_t + \\epsilon}} \\cdot g_t\n",
    "$$\n",
    "where $E[\\cdot]_t$ denotes an exponential moving average. AdaDelta dynamically adapts the learning rate without requiring a manually set base rate $\\eta$.\n",
    "\n",
    "\n",
    "\n",
    "### 4. **RMSprop (Root Mean Square Propagation)**\n",
    "\n",
    "RMSprop maintains an exponentially weighted moving average of squared gradients:\n",
    "$$\n",
    "E[g^2]_t = \\rho E[g^2]_{t-1} + (1 - \\rho) g_t^2, \\quad \\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{E[g^2]_t + \\epsilon}} \\cdot g_t\n",
    "$$\n",
    "This approach stabilizes the gradient updates, especially in non-convex settings. RMSprop was designed for online learning and is particularly effective in training RNNs and deep models.\n",
    "\n",
    "\n",
    "\n",
    "### 5. **Adam (Adaptive Moment Estimation)**\n",
    "\n",
    "Adam combines the ideas of **momentum** and **adaptive learning rates**:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "m_t &= \\beta_1 m_{t-1} + (1 - \\beta_1) g_t \\quad &\\text{(1st moment)} \\\\\n",
    "v_t &= \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2 \\quad &\\text{(2nd moment)} \\\\\n",
    "\\hat{m}_t &= \\frac{m_t}{1 - \\beta_1^t}, \\quad \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t} \\\\\n",
    "\\theta_{t+1} &= \\theta_t - \\eta \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Adam is widely used in deep learning due to its **adaptive nature**, **bias correction**, and **robust convergence behavior**.\n",
    "\n",
    "\n",
    "\n",
    "### 6. **AdamW**\n",
    "\n",
    "AdamW decouples the weight decay regularization from the gradient update:\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - \\eta \\left( \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon} + \\lambda \\theta_t \\right)\n",
    "$$\n",
    "This **decoupled weight decay** leads to more principled control over generalization and stability, especially in deep networks. It is now the default optimizer in many modern training pipelines (e.g., in HuggingFace transformers).\n",
    "\n",
    "\n",
    "\n",
    "### 7. **LBFGS (Limited-memory BFGS)**\n",
    "\n",
    "**L-BFGS** is a quasi-Newton method that approximates the inverse Hessian using a limited memory history of gradients and updates:\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - H_t^{-1} \\nabla f(\\theta_t)\n",
    "$$\n",
    "Here, $H_t^{-1}$ is not computed explicitly, but approximated using a series of updates (via the BroydenFletcherGoldfarbShanno formula). L-BFGS is particularly effective for smooth, convex objectives and has faster convergence than first-order methods when applicable.\n",
    "\n",
    "- Limitation: Less scalable for very large models (e.g., deep nets) due to need for curvature estimation.\n",
    "\n",
    "\n",
    "\n",
    "### A Summary\n",
    "\n",
    "| Optimizer | Type | Key Idea | Suitable For |\n",
    "|---|---|---|---|\n",
    "| GD / SGD | First-order | Uniform learning rate | Smooth convex loss |\n",
    "| Adagrad | Adaptive | Learning rate decays per parameter | Sparse features |\n",
    "| RMSprop | Adaptive | Decaying average of squared grads | RNNs, noisy gradients |\n",
    "| Adam | Adaptive + Momentum | First and second moment estimation | Deep learning |\n",
    "| AdamW | Adam + Weight Decay | Decouples regularization | Transformer models |\n",
    "| AdaDelta | Adagrad variant | Decaying averages only | Adaptive without $\\eta$ |\n",
    "| LBFGS | Quasi-Newton | Hessian approximation | Convex, smooth optimization |\n",
    "\n",
    "\n",
    "Optimizers play a central role in shaping **learning dynamics**, **generalization**, and **training efficiency**. While adaptive methods like **Adam** offer fast convergence and robust performance in high-dimensional, non-convex settings, they can sometimes **overfit** or fail to generalize well. In contrast, simpler methods like **SGD with momentum** may converge more slowly but often yield **better generalization**.\n",
    "\n",
    "Understanding the geometry of the optimization landscape (e.g., curvature, saddle points, plateaus) is crucial when selecting or tuning optimizers in practice.\n",
    "\n",
    "For deeper theoretical insights, see:\n",
    "- [Sebastian Ruder, \"An overview of gradient descent optimization algorithms\"](https://arxiv.org/abs/1609.04747)\n",
    "- [Kingma & Ba, \"Adam: A Method for Stochastic Optimization\"](https://arxiv.org/abs/1412.6980)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dec37f21-1346-4235-a3f4-c64726f32607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 131, number of negative: 1216\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 832\n",
      "[LightGBM] [Info] Number of data points in the train set: 1347, number of used features: 53\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.097253 -> initscore=-2.228125\n",
      "[LightGBM] [Info] Start training from score -2.228125\n",
      "[LightGBM] [Info] Number of positive: 135, number of negative: 1212\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 832\n",
      "[LightGBM] [Info] Number of data points in the train set: 1347, number of used features: 53\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100223 -> initscore=-2.194752\n",
      "[LightGBM] [Info] Start training from score -2.194752\n",
      "[LightGBM] [Info] Number of positive: 131, number of negative: 1216\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 832\n",
      "[LightGBM] [Info] Number of data points in the train set: 1347, number of used features: 53\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.097253 -> initscore=-2.228125\n",
      "[LightGBM] [Info] Start training from score -2.228125\n",
      "[LightGBM] [Info] Number of positive: 145, number of negative: 1202\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 832\n",
      "[LightGBM] [Info] Number of data points in the train set: 1347, number of used features: 53\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.107647 -> initscore=-2.115008\n",
      "[LightGBM] [Info] Start training from score -2.115008\n",
      "[LightGBM] [Info] Number of positive: 127, number of negative: 1220\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 832\n",
      "[LightGBM] [Info] Number of data points in the train set: 1347, number of used features: 53\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.094284 -> initscore=-2.262419\n",
      "[LightGBM] [Info] Start training from score -2.262419\n",
      "[LightGBM] [Info] Number of positive: 143, number of negative: 1204\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 832\n",
      "[LightGBM] [Info] Number of data points in the train set: 1347, number of used features: 53\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.106162 -> initscore=-2.130560\n",
      "[LightGBM] [Info] Start training from score -2.130560\n",
      "[LightGBM] [Info] Number of positive: 139, number of negative: 1208\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 832\n",
      "[LightGBM] [Info] Number of data points in the train set: 1347, number of used features: 53\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.103192 -> initscore=-2.162247\n",
      "[LightGBM] [Info] Start training from score -2.162247\n",
      "[LightGBM] [Info] Number of positive: 135, number of negative: 1212\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 832\n",
      "[LightGBM] [Info] Number of data points in the train set: 1347, number of used features: 53\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100223 -> initscore=-2.194752\n",
      "[LightGBM] [Info] Start training from score -2.194752\n",
      "[LightGBM] [Info] Number of positive: 125, number of negative: 1222\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000237 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 832\n",
      "[LightGBM] [Info] Number of data points in the train set: 1347, number of used features: 53\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.092799 -> initscore=-2.279930\n",
      "[LightGBM] [Info] Start training from score -2.279930\n",
      "[LightGBM] [Info] Number of positive: 136, number of negative: 1211\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000315 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 832\n",
      "[LightGBM] [Info] Number of data points in the train set: 1347, number of used features: 53\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.100965 -> initscore=-2.186547\n",
      "[LightGBM] [Info] Start training from score -2.186547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      1.00      1.00        47\n",
      "           2       1.00      1.00      1.00        46\n",
      "           3       1.00      1.00      1.00        38\n",
      "           4       1.00      1.00      1.00        54\n",
      "           5       0.97      0.95      0.96        39\n",
      "           6       1.00      1.00      1.00        42\n",
      "           7       0.98      0.98      0.98        44\n",
      "           8       1.00      0.98      0.99        49\n",
      "           9       0.93      0.98      0.96        44\n",
      "\n",
      "    accuracy                           0.99       450\n",
      "   macro avg       0.99      0.99      0.99       450\n",
      "weighted avg       0.99      0.99      0.99       450\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaygun/.local/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/kaygun/.local/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/kaygun/.local/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/kaygun/.local/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/kaygun/.local/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/kaygun/.local/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/kaygun/.local/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/kaygun/.local/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/kaygun/.local/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/kaygun/.local/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2ad874-7afe-47a5-9de6-538f9564c360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
